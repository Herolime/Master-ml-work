{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b52d7c7a",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a7cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a122df",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223fb6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        1     4.0\n",
       "1       1        3     4.0\n",
       "2       1        6     4.0\n",
       "3       1       47     5.0\n",
       "4       1       50     5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_relative = 'data_sources'\n",
    "df_ratings =pd.read_csv(path_relative + '/ml-latest-small/ratings.csv')\n",
    "df_ratings = df_ratings[['userId', 'movieId', 'rating']]\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0376d0",
   "metadata": {},
   "source": [
    "## Pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04a51b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>193565</th>\n",
       "      <th>193567</th>\n",
       "      <th>193571</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8       \\\n",
       "userId                                                                    \n",
       "1           4.0     NaN     4.0     NaN     NaN     4.0     NaN     NaN   \n",
       "2           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5           4.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  9       10      ...  193565  193567  193571  193573  193579  193581  \\\n",
       "userId                   ...                                                   \n",
       "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  193583  193585  193587  193609  \n",
       "userId                                   \n",
       "1           NaN     NaN     NaN     NaN  \n",
       "2           NaN     NaN     NaN     NaN  \n",
       "3           NaN     NaN     NaN     NaN  \n",
       "4           NaN     NaN     NaN     NaN  \n",
       "5           NaN     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 9724 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = pd.pivot_table(df_ratings, values='rating', index=['userId'], columns=['movieId'], aggfunc=np.sum)\n",
    "df_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c187d1",
   "metadata": {},
   "source": [
    "### Deal with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4972b29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>193565</th>\n",
       "      <th>193567</th>\n",
       "      <th>193571</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8       \\\n",
       "userId                                                                    \n",
       "1           4.0    -1.0     4.0    -1.0    -1.0     4.0    -1.0    -1.0   \n",
       "2          -1.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "3          -1.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "4          -1.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "5           4.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "\n",
       "movieId  9       10      ...  193565  193567  193571  193573  193579  193581  \\\n",
       "userId                   ...                                                   \n",
       "1          -1.0    -1.0  ...    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "2          -1.0    -1.0  ...    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "3          -1.0    -1.0  ...    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "4          -1.0    -1.0  ...    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "5          -1.0    -1.0  ...    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "\n",
       "movieId  193583  193585  193587  193609  \n",
       "userId                                   \n",
       "1          -1.0    -1.0    -1.0    -1.0  \n",
       "2          -1.0    -1.0    -1.0    -1.0  \n",
       "3          -1.0    -1.0    -1.0    -1.0  \n",
       "4          -1.0    -1.0    -1.0    -1.0  \n",
       "5          -1.0    -1.0    -1.0    -1.0  \n",
       "\n",
       "[5 rows x 9724 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = df_input.fillna(-1)\n",
    "df_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6248bb04",
   "metadata": {},
   "source": [
    "# Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36faf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_input.sample(frac=1).round() #Round ratings\n",
    "len_train = int(np.round(0.8*len(X)))\n",
    "X_train = X.head(len_train)\n",
    "X_test = X.tail(len_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e68cce",
   "metadata": {},
   "source": [
    "## Converting to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21d0a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = X_train.values\n",
    "test_set = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5190397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57df0e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [ 5., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [ 4.,  4., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f02122f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [ 2.,  0., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a5b7d7",
   "metadata": {},
   "source": [
    "## Convert the ratings into binary ratings 1 (Liked) or 0 (Did not liked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2957b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [ 0.,  0., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
      "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [ 1.,  1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1\n",
    "print(test_set)\n",
    "print(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b422085b",
   "metadata": {},
   "source": [
    "# Building the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0924cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, nv, nh, batch_size, nb_epoch, k_steps, learning_rate, verbose):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(1, nh)\n",
    "        self.b = torch.randn(1, nv)\n",
    "        self.nh = nh\n",
    "        self.nv = nv\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_epoch = nb_epoch\n",
    "        self.k_steps = k_steps\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    \n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W) # ojo con esto\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    \n",
    "    def update_weights(self, v0, vk, ph0, phk):\n",
    "        learning_rate = self.learning_rate\n",
    "        self.W += learning_rate*(torch.t(torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)))\n",
    "        self.b += learning_rate*(torch.sum((v0 - vk), 0))\n",
    "        self.a += learning_rate*(torch.sum((ph0 - phk), 0))\n",
    "        \n",
    "    def train(self, training_set):\n",
    "        batch_size = self.batch_size\n",
    "        nb_epoch = self.nb_epoch\n",
    "        k_steps = self.k_steps\n",
    "        verbose = self.verbose\n",
    "        \n",
    "        #Training the RBM\n",
    "        \n",
    "        for epoch in range(1, nb_epoch, + 1):\n",
    "            train_loss = 0\n",
    "            s = 0.\n",
    "            nb_users = len(training_set)\n",
    "            for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "                vk = training_set[id_user: id_user+batch_size]\n",
    "                v0 = training_set[id_user: id_user+batch_size]\n",
    "                ph0,_ = self.sample_h(v0)\n",
    "                for k in range(k_steps):\n",
    "                    _,hk = self.sample_h(vk)\n",
    "                    _,vk = self.sample_v(hk)\n",
    "                    vk[v0<0] = v0[v0<0]\n",
    "                phk,_ = self.sample_h(vk)\n",
    "                self.update_weights(v0, vk, ph0, phk)\n",
    "                train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
    "                s += 1.\n",
    "            if verbose:\n",
    "                print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
    "                \n",
    "    \n",
    "    def evaluate(self, test_set):\n",
    "        verbose = self.verbose\n",
    "        nb_users = len(test_set)\n",
    "        \n",
    "        #testing the RBM\n",
    "        test_loss = 0\n",
    "        s = 0.\n",
    "        \n",
    "        for id_user in range(nb_users):\n",
    "            v = training_set[id_user: id_user+1]\n",
    "            vt = test_set[id_user: id_user+1]\n",
    "            if len(vt[vt>=0]) > 0:\n",
    "                _,h = self.sample_h(v)\n",
    "                _,v = self.sample_v(h)\n",
    "                test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "                s+= 1.\n",
    "        if verbose:\n",
    "            print('test loss: '+str(test_loss/s))\n",
    "        return test_loss/s\n",
    "    \n",
    "    def predict(self, v_user):\n",
    "        _,h = self.sample_h(v_user)\n",
    "        _,v = self.sample_v(h)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871ac3b1",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3df4dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = len(training_set[0])\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "nb_epoch = 10\n",
    "k_steps = 10\n",
    "learning_rate = 1\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bedaa9c",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9abc3e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.4586)\n",
      "epoch: 2 loss: tensor(0.3094)\n",
      "epoch: 3 loss: tensor(0.2692)\n",
      "epoch: 4 loss: tensor(0.2540)\n",
      "epoch: 5 loss: tensor(0.2399)\n",
      "epoch: 6 loss: tensor(0.2339)\n",
      "epoch: 7 loss: tensor(0.2336)\n",
      "epoch: 8 loss: tensor(0.2294)\n",
      "epoch: 9 loss: tensor(0.2284)\n"
     ]
    }
   ],
   "source": [
    "rbm = RBM(nv, nh, batch_size, nb_epoch, k_steps, learning_rate, verbose)\n",
    "rbm.train(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef879c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9887cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.2407)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2407)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4279facd",
   "metadata": {},
   "source": [
    "### Obtain an individual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7fa5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_test = test_set[0:1]\n",
    "v_pred = rbm.predict(v_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928af03",
   "metadata": {},
   "source": [
    "#### Check movie for that prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a34e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_movies = ([v_pred==1][0][0]) & ([v_test==-1][0][0])\n",
    "id_movies = id_movies.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99299c49",
   "metadata": {},
   "source": [
    "#### Combine with movie titles and see results for units with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc36227f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies: \n",
      "0                       Toy Story (1995)\n",
      "1                         Jumanji (1995)\n",
      "2                Grumpier Old Men (1995)\n",
      "6                         Sabrina (1995)\n",
      "7                    Tom and Huck (1995)\n",
      "10        American President, The (1995)\n",
      "11    Dracula: Dead and Loving It (1995)\n",
      "12                          Balto (1995)\n",
      "15                         Casino (1995)\n",
      "16          Sense and Sensibility (1995)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_recom = pd.DataFrame({'id_check': id_movies})\n",
    "df_movies = pd.read_csv(path_relative  + '/ml-latest-small/movies.csv')\n",
    "df_recom = df_recom.reset_index().rename(columns={'index':'movieId'}).merge(df_movies)\n",
    "\n",
    "print('Recommended movies: ')\n",
    "print(df_recom[df_recom['id_check']==True]['title'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03431668",
   "metadata": {},
   "source": [
    "# Building the RBM\n",
    "## (_Using tensorflow_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a22b85",
   "metadata": {},
   "source": [
    "### Class that defines the behavior of the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7542faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class RBM_tensorflow(object):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, lr=1.0, batchsize=100):\n",
    "        \"\"\"\n",
    "        m: Number of neurons in visible layer\n",
    "        n: Number of neurons in hidden layer\n",
    "        \"\"\"\n",
    "        \n",
    "        #Defining the hyperparameters\n",
    "        self._input_size = input_size #Size of Visible\n",
    "        self._output_size = output_size #Size of output\n",
    "        self.learning_rate = lr #The step used in gradient descient\n",
    "        self.batchsize = batchsize #The size of how much data will be used for training per sub iteration\n",
    "        \n",
    "        #Initializing weights and biases as matrices full of zeroes\n",
    "        self.w = tf.zeros([input_size, output_size], np.float32) #Creates and initializes the weights with 0\n",
    "        self.hb = tf.zeros([output_size], np.float32) #Creates and initializes the hidden biases with 0\n",
    "        self.vb = tf.zeros([input_size], np.float32) #Creates and initalizes the visible biases with 0\n",
    "        \n",
    "    #Forward Pass\n",
    "    def prob_h_given_v(self, visible, w, hb):\n",
    "        #Sigmoid\n",
    "        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n",
    "    \n",
    "    #Backward Pass\n",
    "    def prob_v_given_h(self, hidden, w, vb):\n",
    "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
    "    \n",
    "    #Generate the sample probability\n",
    "    def sample_prob(self, probs):\n",
    "        return tf.nn.relu(tf.sign(probs - tf.random.uniform(tf.shape(probs))))\n",
    "    \n",
    "    #Training method for the model\n",
    "    def train(self, X, epochs=10):\n",
    "        loss=[]\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            #For each step/batch\n",
    "            for start, end in zip(range(0, len(X), self.batchsize), range(self.batchsize, len(X), self.batchsize)):\n",
    "                batch = X[start:end]\n",
    "                \n",
    "                #Initialize with sample probabilities\n",
    "                h0 = self.sample_prob(self.prob_h_given_v(batch, self.w, self.hb))\n",
    "                v1 = self.sample_prob(self.prob_v_given_h(h0, self.w, self.vb))\n",
    "                h1 = self.prob_h_given_v(v1, self.w, self.hb)\n",
    "                \n",
    "                #Create the Gradients\n",
    "                positive_grad = tf.matmul(tf.transpose(batch), h0)\n",
    "                negative_grad = tf.matmul(tf.transpose(v1), h1)\n",
    "                \n",
    "                #Update learning rates\n",
    "                self.w = self.w + self.learning_rate * (positive_grad - negative_grad) / tf.dtypes.cast(tf.shape(batch)[0], tf.float32)\n",
    "                self.vb = self.vb + self.learning_rate * tf.reduce_mean(batch - v1, 0)\n",
    "                self.hb = self.hb + self.learning_rate * tf.reduce_mean(h0 - h1, 0)\n",
    "            \n",
    "            #Find the error rate\n",
    "            err = tf.reduce_mean(tf.square(batch - v1))\n",
    "            print ('Epoch: %d' % epoch, 'reconstruction error: %f' % err)\n",
    "            loss.append(err)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    #Create expected output for our DBN\n",
    "    def rbm_output(self, X):\n",
    "        out = tf.nn.sigmoid(tf.matmul(X, self.w) + self.hb)\n",
    "        return out\n",
    "    \n",
    "    def rbm_reconstruct(self, X):\n",
    "        h = tf.nn.sigmoid(tf.matmul(X, self.w) + self.hb)\n",
    "        reconstruct = tf.nn.sigmoid(tf.matmul(h, tf.transpose(self.w)) + self.vb)\n",
    "        return reconstruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7dc931",
   "metadata": {},
   "source": [
    "## Train tensorflow model \n",
    "### _(We'll use the same hyperparameters as previous model)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "508267db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 reconstruction error: 0.995984\n",
      "Epoch: 1 reconstruction error: 0.995984\n",
      "Epoch: 2 reconstruction error: 0.995984\n",
      "Epoch: 3 reconstruction error: 0.995984\n",
      "Epoch: 4 reconstruction error: 0.995984\n",
      "Epoch: 5 reconstruction error: 0.995984\n",
      "Epoch: 6 reconstruction error: 0.995984\n",
      "Epoch: 7 reconstruction error: 0.995984\n",
      "Epoch: 8 reconstruction error: 0.995984\n",
      "Epoch: 9 reconstruction error: 0.995984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.99598414>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.99598414>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.99598414>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.99598414>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.99598414>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.99598414>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.99598414>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.99598414>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.99598414>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.99598414>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm_tensorflow = RBM_tensorflow(nv, nh, 1.0, batch_size)\n",
    "rbm_tensorflow.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98730475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
